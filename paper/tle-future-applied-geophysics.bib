
@book{national_academies_of_sciences_reproducibility_2019,
	address = {Washington, DC},
	title = {Reproducibility and {Replicability} in {Science}},
	isbn = {978-0-309-48616-3},
	url = {https://www.nap.edu/catalog/25303/reproducibility-and-replicability-in-science},
	abstract = {One of the pathways by which the scientific community confirms the validity of a new scientific discovery is by repeating the research that produced it. When a scientific effort fails to independently confirm the computations or results of a previous study, some fear that it may be a symptom of a lack of rigor in science, while others argue that such an observed inconsistency can be an important precursor to new discovery.{\textbackslash}nConcerns about reproducibility and replicability have been expressed in both scientific and popular media. As these concerns came to light, Congress requested that the National Academies of Sciences, Engineering, and Medicine conduct a study to assess the extent of issues related to reproducibility and replicability and to offer recommendations for improving rigor and transparency in scientific research.{\textbackslash}nReproducibility and Replicability in Science defines reproducibility and replicability and examines the factors that may lead to non-reproducibility and non-replicability in research. Unlike the typical expectation of reproducibility between two computations, expectations about replicability are more nuanced, and in some cases a lack of replicability can aid the process of scientific discovery. This report provides recommendations to researchers, academic institutions, journals, and funders on steps they can take to improve reproducibility and replicability in science.},
	publisher = {The National Academies Press},
	author = {National Academies of Sciences, Engineering, \{and\} Medicine},
	year = {2019},
	doi = {10.17226/25303},
	file = {PDF:/Users/lindseyjh/Zotero/storage/F2XQPRZ8/ National Academies of Sciences, Engineering_2019_Reproducibility and Replicability in Science.pdf:application/pdf},
}

@article{Astic2019,
	title = {A framework for petrophysically and geologically guided geophysical inversion using a dynamic {Gaussian} mixture model prior},
	volume = {219},
	issn = {1365246X},
	doi = {10.1093/gji/ggz389},
	abstract = {We propose a new framework for incorporating petrophysical and geological information into voxel-based geophysical inversion. By developing the geophysical inverse problem from a probabilistic perspective, we redesign the objective function and the iteration steps as a suite of cyclic optimization problems in which three separate MAP optimization problems are solved using geophysical, petrophysical and geological data, respectively. By quantitatively linking these data into a single framework, we recover a final inverted model that reproduces the observed, or desired, petrophysical and geological features while fitting the geophysical data. To achieve our goal we replace the Gaussian prior, used in the Tikhonov inversion approach, by a Gaussian mixture model. After each geophysical model update, the mixture parameters (means, variances and proportions) are determined by the geophysical model and the expected characteristics of the lithologies through another optimization process using the expectation–maximization algorithm. We then classify the model cells into rock units according to the petrophysical and geological information. These two additional steps over the petrophysical and geological data result in a dynamic update of the reference model and associated weights and guide the inversion towards reproducing the expected petrophysical and geological characteristics. The resulting geophysical objective function does not require extra terms to include the additional petrophysical and geological information; this is an important distinction between our work and previous frameworks that carry out joint geophysical and petrophysical data inversion.We highlight different capabilities of our methodology by inverting magnetotelluric and direct-current resistivity data in 1-D and 2-D, respectively. Finally, we apply our framework to inverting airborne frequency domain data, acquired in Australia, for the detection and characterization of saline contamination of freshwater.},
	number = {3},
	journal = {Geophysical Journal International},
	author = {Astic, Thibaut and Oldenburg, Douglas W},
	year = {2019},
	note = {Publisher: Oxford University Press},
	keywords = {Electrical properties, Inverse theory, Joint Inversion, Non-linear electromagnetics, Probability distributions},
	pages = {1989--2012},
	file = {PDF:/Users/lindseyjh/Zotero/storage/PD3LVN8R/Astic, Oldenburg_2019_A framework for petrophysically and geologically guided geophysical inversion using a dynamic Gaussian mixture (2).pdf:application/pdf},
}

@article{Hunter2007,
	title = {Matplotlib: {A} {2D} graphics environment},
	volume = {9},
	issn = {1521-9615},
	url = {http://ieeexplore.ieee.org/document/4160265/},
	doi = {10.1109/MCSE.2007.55},
	abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.},
	number = {3},
	journal = {Computing In Science \& Engineering},
	author = {Hunter, J D},
	year = {2007},
	note = {Publisher: IEEE COMPUTER SOC},
	pages = {90--95},
}

@article{Rucker2017,
	title = {{pyGIMLi}: {An} open-source library for modelling and inversion in geophysics},
	volume = {109},
	issn = {00983004},
	url = {https://doi.org/10.1016/j.cageo.2017.07.011},
	doi = {10.1016/j.cageo.2017.07.011},
	abstract = {Many tasks in applied geosciences cannot be solved by single measurements, but require the integration of geophysical, geotechnical and hydrological methods. Numerical simulation techniques are essential both for planning and interpretation, as well as for the process understanding of modern geophysical methods. These trends encourage open, simple, and modern software architectures aiming at a uniform interface for interdisciplinary and flexible modelling and inversion approaches. We present pyGIMLi (Python Library for Inversion and Modelling in Geophysics), an open-source framework that provides tools for modelling and inversion of various geophysical but also hydrological methods. The modelling component supplies discretization management and the numerical basis for finite-element and finite-volume solvers in 1D, 2D and 3D on arbitrarily structured meshes. The generalized inversion framework solves the minimization problem with a Gauss-Newton algorithm for any physical forward operator and provides opportunities for uncertainty and resolution analyses. More general requirements, such as flexible regularization strategies, time-lapse processing and different sorts of coupling individual methods are provided independently of the actual methods used. The usage of pyGIMLi is first demonstrated by solving the steady-state heat equation, followed by a demonstration of more complex capabilities for the combination of different geophysical data sets. A fully coupled hydrogeophysical inversion of electrical resistivity tomography (ERT) data of a simulated tracer experiment is presented that allows to directly reconstruct the underlying hydraulic conductivity distribution of the aquifer. Another example demonstrates the improvement of jointly inverting ERT and ultrasonic data with respect to saturation by a new approach that incorporates petrophysical relations in the inversion. Potential applications of the presented framework are manifold and include time-lapse, constrained, joint, and coupled inversions of various geophysical and hydrological data sets.},
	number = {July},
	journal = {Computers and Geosciences},
	author = {Rücker, Carsten and Günther, Thomas and Wagner, Florian M.},
	year = {2017},
	note = {Publisher: The Authors},
	pages = {106--123},
	file = {PDF:/Users/lindseyjh/Zotero/storage/YX4UJ3W5/Rücker, Günther, Wagner_2017_pyGIMLi An open-source library for modelling and inversion in geophysics.pdf:application/pdf},
}

@article{oldenburg_3d_2020,
	title = {{3D} electromagnetic modelling and inversion: a case for open source},
	volume = {51},
	copyright = {All rights reserved},
	issn = {0812-3985},
	shorttitle = {{3D} electromagnetic modelling and inversion},
	url = {https://doi.org/10.1080/08123985.2019.1580118},
	doi = {10.1080/08123985.2019.1580118},
	abstract = {Electromagnetics has an important role to play in solving the next generation of geoscience problems. These problems are multidisciplinary, complex, and require collaboration. This is especially true at the base scientific level, where the underlying physical equations need to be solved, and data, associated with physical experiments, need to be inverted. In this paper, we present arguments for adopting an open-source methodology for geophysics and provide some background about open-source software for electromagnetics. Immediate benefits are the reduced time required to carry out research, being able to collaborate, having reproducible results, and being able to disseminate results quickly. To illustrate the use of an open-source methodology in electromagnetics, we present two challenges. The first is to simulate data from a time-domain airborne system over a conductive plate buried in a more resistive earth. The second is to jointly invert airborne time-domain electromagnetic (TDEM) and frequency-domain electromagnetic (FDEM) data with ground TDEM. SimPEG (Simulation and Parameter Estimation in Geophysics, https://simpeg.xyz) is used for the open-source software. The figures in this paper can be reproduced by downloading the Jupyter notebooks we provide with this paper (https://github.com/simpeg-research/oldenburg-2018-AEM). Access to the source code allows the researcher to explore simulations and inversions by changing model and inversion parameters, plot fields and fluxes to gain further insight on the electromagnetic phenomena, and solve a new research problem by using open-source software as a base. By providing results in a manner that allows others to reproduce, further explore, and even extend them, we hope to demonstrate that an open-source paradigm has the potential to enable more rapid progress in the geophysics community as a whole.},
	number = {0},
	journal = {Exploration Geophysics},
	author = {Oldenburg, Douglas W and Heagy, Lindsey J and Kang, Seogi and Cockett, Rowan},
	month = jan,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/08123985.2019.1580118},
	keywords = {inversion, 3D modelling, electromagnetic geophysics, programming, airborne electromagnetics},
	pages = {25--37},
	file = {PDF:/Users/lindseyjh/Zotero/storage/LRS5WUHI/Oldenburg et al._2020_3D electromagnetic modelling and inversion a case for open source.pdf:application/pdf;Submitted Version:/Users/lindseyjh/Zotero/storage/9AESYFFB/Oldenburg et al. - 2020 - 3D electromagnetic modelling and inversion a case.pdf:application/pdf},
}

@article{fournier_sparse_2020,
	title = {Sparse magnetic vector inversion in spherical coordinates},
	volume = {85},
	copyright = {All rights reserved},
	issn = {0016-8033},
	url = {https://library.seg.org/doi/10.1190/geo2019-0244.1},
	doi = {10.1190/geo2019-0244.1},
	abstract = {Magnetic vector inversion (MVI) has received considerable attention over recent years for processing magnetic field data that are affected by remanent magnetization. However, the magnetization models obtained with current inversion algorithms are generally too smooth to be easily interpreted geologically. To address this, we have reviewed the MVI formulated in a spherical coordinate system. We tackle convergence issues posed by the nonlinear transformation from Cartesian to spherical coordinates by using an iterative sensitivity weighting approach and a scaling of the spherical parameters. The spherical formulation allows us to impose sparsity assumptions on the magnitude and direction of magnetization independently and, as a result, the inversion recovers simpler and more coherent magnetization orientations. The numerical implementation of our algorithm on large-scale problems is facilitated by discretizing the forward problem using tiled octree meshes. All of our results are generated using the open-source SimPEG software. We determine the enhanced capabilities of our algorithm on a large airborne magnetic survey collected over the Kevitsa Ni-Cu-platinum group elements (PGE) deposit. The recovered magnetization direction inside the ultramafic intrusion and in the host stratigraphy is consistent with laboratory measurements and provides evidence for tectonic deformation.},
	number = {3},
	journal = {GEOPHYSICS},
	author = {Fournier, Dominique and Heagy, Lindsey J. and Oldenburg, Douglas W.},
	month = may,
	year = {2020},
	pages = {J33--J49},
	file = {PDF:/Users/lindseyjh/Zotero/storage/GXDH4ZKX/Fournier, Heagy, Oldenburg_2020_Sparse magnetic vector inversion in spherical coordinates.pdf:application/pdf},
}

@article{numpy,
	title = {The {NumPy} {Array}: {A} {Structure} for {Efficient} {Numerical} {Computation}},
	volume = {13},
	issn = {1521-9615},
	doi = {10.1109/MCSE.2011.37},
	number = {2},
	journal = {Computing in Science Engineering},
	author = {van der Walt, S and Colbert, S C and Varoquaux, G},
	month = mar,
	year = {2011},
	keywords = {Arrays, high level languages, Python, scientific programming, Computational efficiency, data structures, Finite element methods, high level language, mathematics computing, numerical analysis, Numerical analysis, numerical computation, numerical computations, numerical data, NumPy, numpy array, Performance evaluation, programming libraries, Python programming language, Resource management, Vector quantization},
	pages = {22--30},
}

@article{Uieda2013,
	title = {Modeling the {Earth} with {Fatiando} a {Terra}},
	issn = {0016-8033},
	doi = {10.25080/Majora-8b375195-010},
	abstract = {Geophysics is the science of using physical observations of the Earth to infer its inner structure. Generally, this is done with a variety of numerical modeling techniques and inverse problems. The development of new algorithms usually involves copy and pasting of code, which leads to errors and poor code reuse. Fatiando a Terra is a Python library that aims to automate common tasks and unify the modeling pipeline inside of the Python language. This allows users to replace the traditional shell scripting with more versatile and powerful Python scripting. The library can also be used as an API for developing stand-alone programs. Algorithms implemented in Fatiando a Terra can be combined to build upon existing functionality. This flexibility facilitates prototyping of new algorithms and quickly building interactive teaching exercises. In the future, we plan to continuously implement sample problems to help teach geophysics as well as classic and state-of-the-art algorithms.},
	number = {Scipy},
	journal = {Proceedings of the 12th Python in Science Conference},
	author = {Uieda, Leonardo and Oliveira Jr, Vanderlei C. and Barbosa, Valéria C. F.},
	year = {2013},
	pages = {90--96},
	file = {PDF:/Users/lindseyjh/Zotero/storage/JJBJ8HUL/uieda.pdf:application/pdf},
}

@article{Werthmuller2017,
	title = {An open-source full {3D} electromagnetic modeler for {1D} {VTI} media in {Python}: empymod},
	volume = {82},
	issn = {0016-8033},
	url = {http://library.seg.org/doi/10.1190/geo2016-0626.1},
	doi = {10.1190/geo2016-0626.1},
	number = {6},
	journal = {GEOPHYSICS},
	author = {Werthmüller, Dieter},
	month = nov,
	year = {2017},
	pages = {WB9--WB19},
	file = {PDF:/Users/lindseyjh/Zotero/storage/2LQ2RTX7/Werthmüller_2017_An open-source full 3D electromagnetic modeler for 1D VTI media in Python empymod.pdf:application/pdf;Snapshot:/Users/lindseyjh/Zotero/storage/KDELL6RT/An-open-source-full-3D-electromagnetic-modeler-for.html:text/html},
}

@article{Pedregosa2011,
	title = {Scikit-learn: Machine Learning in Python},
	volume = {12},
	issn = {9781783281930},
	url = {https://www.jmlr.org/papers/v12/pedregosa11a.html},
	doi = {https://doi.org/10.48550/arXiv.1201.0490},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learn-ing algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consis-tency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.},
	journal = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot an Edouard Duchesnay Pedregosa, Matthieu and David Cournapeau, al and Perrot matthieuperrot, Matthieu and Edouard Duchesnay, cea},
	year = {2011},
	pmid = {1000044560},
	note = {arXiv: 1201.0490v3
ISBN: 9781783281930},
	keywords = {()},
	pages = {2825--2830},
}

@inproceedings{Claerbout1992,
	title = {Electronic documents give reproducible research a new meaning},
	url = {http://library.seg.org/doi/abs/10.1190/1.1822162},
	doi = {10.1190/1.1822162},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, Jon F. and Karrenbach, Martin},
	month = jan,
	year = {1992},
	pages = {601--604},
}

@incollection{Paszke2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	editor = {Wallach, H and Larochelle, H and Beygelzimer, A and d{\textbackslash}textquotesingle Alché-Buc, F and Fox, E and Garnett, R},
	year = {2019},
	pages = {8024--8035},
}

@article{Gallardo2003,
	title = {Characterization of heterogeneous near-surface materials by joint {2D} inversion of dc resistivity and seismic data},
	volume = {30},
	issn = {00948276},
	doi = {10.1029/2003GL017370},
	abstract = {We have developed a robust 2D joint inversion scheme incorporating the new concept of cross-gradients of electrical resistivity and seismic velocity as constraints so as to investigate more precisely the resistivity-velocity relationships in complex near-surface environments. The results of joint inversion of dc resistivity and seismic traveltime data from collocated experiments suggest that one can distinguish between different types or facies of unconsolidated and consolidated materials, refining a previously proposed resistivity-velocity interrelationship derived from separate inversions of the respective data sets. A consistent interpretive structural model can be obtained from the joint inversion models.},
	number = {13},
	journal = {Geophysical Research Letters},
	author = {Gallardo, Luis A. and Meju, Max A.},
	year = {2003},
	keywords = {http://dx.doi.org/10.1029/2003GL017370, doi:10.102},
	pages = {2--5},
	file = {PDF:/Users/lindseyjh/Zotero/storage/EYE24BIH/Gallardo, Meju_2003_Characterization of heterogeneous near-surface materials by joint 2D inversion of dc resistivity and seismic data.pdf:application/pdf},
}

@article{Sun2016,
	title = {Joint inversion of multiple geophysical data using guided fuzzy c-means clustering},
	volume = {81},
	issn = {19422156},
	doi = {10.1190/GEO2015-0457.1},
	abstract = {Joint inversion of multiple geophysical data has become an active area of research due to its potential to greatly enhance the fidelity of inverted models. Many open questions and challenges still remain. One of them is how to effectively incorporate into joint inversion multimodal petrophysical information that describes the statistical behavior of physical property values in the parameter domain (i.e., in a crossplot).We have regarded the multimodal petrophysical data as different clusters in the parameter domain and developed an approach that handles multimodal petrophysical information through guided fuzzy c-means (FCM) clustering in the parameter domain.We inverted the petrophysical data in the parameter domain in a similar manner to and simultaneously with the geophysical data in the spatial domain through minimizing one common objective function. Numerical examples have determined that the resulting models from this multidomain joint-inversion strategy are able to reproduce both the geophysical and the petrophysical data. In addition to incorporating a priori multimodal petrophysical information into inversion, guided FCMclustering also allows us to integrate geology differentiation and geophysical inversion into one unified framework that makes these two components positively affect each other. Geology differentiation results were obtained as a direct output from joint inversion. We have also developed a strategy for imposing different clustering constraints in different model regions, allowing region-specific a priori petrophysical information to be incorporated into inversion. We have applied our joint-inversion algorithm to the SEG/EAGE salt model in four different scenarios, and we found that the proposed algorithm produced much better geophysical models and geology differentiation results than separate inversions.},
	number = {3},
	journal = {Geophysics},
	author = {Sun, Jiajia and Li, Yaoguo},
	year = {2016},
	pages = {ID37--ID57},
	file = {PDF:/Users/lindseyjh/Zotero/storage/YIUC2DQN/Sun, Li_2016_Joint inversion of multiple geophysical data using guided fuzzy c-means clustering.pdf:application/pdf},
}

@article{Haber2013,
	title = {Model {Fusion} and {Joint} {Inversion}},
	volume = {34},
	issn = {01693298},
	doi = {10.1007/s10712-013-9232-4},
	abstract = {Inverse problems are inherently non-unique, and regularization is needed to obtain stable and reasonable solutions. The regularization adds information to the problem and determines which solution, out of the infinitely many, is obtained. In this paper, we review and discuss the case when a priori information exists in the form of either known structure or in the form of another inverse problem for a different property. The challenge is to include such information in the inversion process. To use existing known structure, we review the concept of model fusion, where we build a regularization functional that fuses the inverted model to a known one. The fusion is achieved by four different techniques. Joint inversion of two data sets is achieved by using iterative data fusion. The paper discusses four different methods for joint inversion. We discuss the use of correspondence maps or the petrophysics of the rocks, as well as structure. In particular, we suggest to further stabilize the well-known gradient cross product and suggest a new technique, Joint Total Variation, to solve the problem. The Joint Total Variation is a convex functional for joint inversion and, as such, has favorable optimization properties. We experiment with the techniques on the DC resistivity problem and the borehole tomography and show how model fusion and joint inversion can significantly improve over existing techniques. © 2013 Springer Science+Business Media Dordrecht.},
	number = {5},
	journal = {Surveys in Geophysics},
	author = {Haber, Eldad and Gazit, Michal H},
	year = {2013},
	keywords = {Joint inversion, Cross product, Model fusion, Total variation},
	pages = {675--695},
	file = {PDF:/Users/lindseyjh/Zotero/storage/DB32YWAG/Haber, Holtzman Gazit_2013_Model Fusion and Joint Inversion.pdf:application/pdf},
}

@article{Virtanen2020,
	title = {{SciPy} 1.0: fundamental algorithms for scientific computing in {Python}},
	volume = {17},
	issn = {1548-7091},
	url = {http://www.nature.com/articles/s41592-019-0686-2},
	doi = {10.1038/s41592-019-0686-2},
	abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
	number = {3},
	journal = {Nature Methods},
	author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, Ilhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul},
	month = mar,
	year = {2020},
	pages = {261--272},
}

@article{fournier_inversion_2019,
	title = {Inversion using spatially variable mixed {Lp} norms},
	volume = {218},
	issn = {0956-540X},
	url = {https://doi.org/10.1093/gji/ggz156},
	doi = {10.1093/gji/ggz156},
	abstract = {Non-uniqueness in the geophysical inverse problem is well recognized and so too is the ability to obtain solutions with different character by altering the form of the regularization function. Of particular note is the use of ℓp norms with p ∈ [0, 2] which gives rise to sparse or smooth models. Most algorithms are designed to implement a single ℓp norm for the entire model domain. This is not adequate when the fundamental character of the model changes throughout the volume of interest. In such cases we require a generalized regularization function where each sub-volume of the model domain has penalties on smallness and roughness and its own suite of ℓp parameters.Solving the inverse problem using mixed ℓp norms in the regularization (especially for p {\textbackslash}{\textbackslash}\&lt; 1) is computationally challenging. We use the Lawson formulation for the ℓp norm and solve the optimization problem with Iterative Reweighted Least Squares. The algorithm has two stages; we first solve the l2-norm problem and then we switch to the desired suite of ℓp norms; there is one value of p for each term in the objective function. To handle the large changes in numerical values of the regularization function when p values are changed, and to ensure that each component of the regularization is contributing to the final solution, we successively rescale the gradients in our Gauss–Newton solution. An indicator function allows us to evaluate our success in finding a solution in which components of the objective function have been equally influential.We use our algorithm to generate an ensemble of solutions with mixed ℓp norms. This illuminates some of the non-uniqueness in the inverse problem and helps prevent overinterpretation that can occur by having only one solution. In addition, we use this ensemble to estimate the suite of p values that can be used in a final inversion. First, the most common features of our ensemble are extracted using principal component analysis and edge detection procedures; this provides a reference model. A correlation of each member of the ensemble with the reference model, carried out in a windowed domain, then yields a set of p values for each model cell. The efficacy of our technique is illustrated on a synthetic 2-D cross-well example. We then apply our technique to the field example that motivated this research, the 3-D inversion of magnetic data at a kimberlite site in Canada. Since the final regularization terms have different sets of p values in different regions of model space we are able to recover compact regions associated with the kimberlite intrusions, continuous linear features with sharp edges that are associated with dykes and a background that is relatively smooth. The result has a geologic character that would not have been achievable without the use of spatially variable mixed norms.},
	number = {1},
	journal = {Geophysical Journal International},
	author = {Fournier, Dominique and Oldenburg, Douglas W.},
	year = {2019},
	keywords = {Tomography, Inverse theory, Numerical modelling, Magnetic anomalies: modelling and interpretation, North America},
	pages = {268--282},
	file = {Fournier, Oldenburg_2019_Inversion using spatially variable mixed ℓp norms.pdf:/Users/lindseyjh/Zotero/storage/U6TMTN26/Fournier, Oldenburg_2019_Inversion using spatially variable mixed ℓp norms.pdf:application/pdf;PDF:/Users/lindseyjh/Zotero/storage/5GU67DSE/Fournier, Oldenburg_2019_Inversion using spatially variable mixed ℓp norms(2).pdf:application/pdf},
}

@article{Oldenburg2021,
	title = {Geophysical electromagnetics: {A} retrospective, {DISC} 2017, and a look forward},
	volume = {40},
	copyright = {All rights reserved},
	issn = {1070-485X},
	doi = {10.1190/tle40020140.1},
	abstract = {Geophysical electromagnetics (EM) plays an important role in mineral exploration and is increasingly being used to help solve other problems of relevance to society. In this article we reflect, from our perspective at the University of British Columbia, on the development of EM geophysics over the years, on our attempts to enhance understanding of EM geophysics, and on its visibility and usefulness to the community. The availability of open-source resources and a shift within the EM community toward collaborative practices for sharing and creating software and educational resources have been drivers of progress toward these goals. In this article, we provide background about this trajectory and discuss how the SEG Distinguished Instructor Short Course was a catalyst in our development of software and resources as well as in our broader goal of creating more collaborative connections within the EM community.},
	number = {2},
	journal = {The Leading Edge},
	author = {Oldenburg, Douglas W. and Heagy, Lindsey J. and Kang, Seogi},
	year = {2021},
	keywords = {electromagnetics, mining, CSEM, electrical resistivity, magnetotelluric},
	pages = {140--148},
	file = {PDF:/Users/lindseyjh/Zotero/storage/UFJBP323/Oldenburg, Heagy, Kang_2021_Geophysical electromagnetics A retrospective, DISC 2017, and a look forward.pdf:application/pdf;PDF:/Users/lindseyjh/Zotero/storage/F979QWIV/Oldenburg, Heagy, Kang_2021_Geophysical electromagnetics A retrospective, DISC 2017, and a look forward(2).pdf:application/pdf},
}

@article{Werthmuller2020,
	title = {Towards an open-source landscape for {3D} {CSEM} modelling},
	copyright = {All rights reserved},
	issn = {0956-540X},
	url = {https://github.com/swung-research/3d-csem-open-source-landscape},
	doi = {10.1093/gji/ggab238},
	abstract = {Large-scale modelling of three-dimensional controlled-source electromagnetic (CSEM) surveys used to be feasible only for large companies and research consortia. This has changed over the last few years, and today there exists a selection of different open-source codes available to everyone. Using four different codes in the Python ecosystem, we perform simulations for increasingly complex models in a shallow marine setting. We first verify the computed fields with semi-analytical solutions for a simple layered model. Then we validate the responses of a more complex block model by comparing results obtained from each code. Finally we compare the responses of a real world model with results from the industry. On the one hand, these validations show that the open-source codes are able to compute comparable CSEM responses for challenging, large-scale models. On the other hand, they show many general and method-dependent problems that need to be faced for obtaining accurate results. Our comparison includes finite-element and finite-volume codes using structured rectilinear and octree meshes as well as unstructured tetrahedral meshes. Accurate responses can be obtained independently of the chosen method and the chosen mesh type. The runtime and memory requirements vary greatly based on the choice of iterative or direct solvers. However, we have found that much more time was spent on designing the mesh and setting up the simulations than running the actual computation. The challenging task is, irrespective of the chosen code, to appropriately discretize the model. We provide three models, each with their corresponding discretization and responses of four codes, which can be used for validation of new and existing codes. The collaboration of four code maintainers trying to achieve the same task brought in the end all four codes a significant step further. This includes improved meshing and interpolation capabilities, resulting in shorter runtimes for the same accuracy. We hope that these results may be useful for the CSEM community at large and that we can build over time a suite of benchmarks that will help to increase the confidence in existing and new 3D CSEM codes.},
	journal = {Geophysical Journal International},
	author = {Werthmüller, Dieter and Rochlitz, Raphael and Castillo-Reyes, Octavio and Heagy, Lindsey},
	month = jun,
	year = {2021},
	note = {arXiv: 2010.12926},
	keywords = {csem, controlled source electromagnetics, electrical properties, elling, numerical mod-},
	pages = {1--18},
	file = {PDF:/Users/lindseyjh/Zotero/storage/ZAAZPZS3/Werthmüller et al._2020_Towards an open-source landscape for 3D CSEM modelling.pdf:application/pdf},
}

@article{Oldenburg2005,
	title = {Inversion for applied geophysics: {A} tutorial},
	volume = {13},
	url = {http://library.seg.org/doi/book/10.1190/1.9781560801719},
	doi = {10.1190/1.9781560801719.ch5},
	urldate = {2014-04-16},
	journal = {Investigations in geophysics},
	author = {Oldenburg, Douglas W. and Li, Yaoguo},
	editor = {Butler, Dwain K.},
	month = jan,
	year = {2005},
	note = {Publisher: Society of Exploration Geophysicists
ISBN: 978-1-56080-130-6},
	pages = {1--85},
	file = {PDF:/Users/lindseyjh/Zotero/storage/U3LCFQF6/Oldenburg-Li-tutorial.pdf:application/pdf},
}

@article{cockett_simpeg_2015,
	title = {{SimPEG}: {An} open source framework for simulation and gradient based parameter estimation in geophysical applications},
	volume = {85},
	copyright = {All rights reserved},
	issn = {00983004},
	url = {https://simpeg.xyz},
	doi = {10.1016/j.cageo.2015.09.015},
	journal = {Computers \& Geosciences},
	author = {Cockett, Rowan and Kang, Seogi and Heagy, Lindsey J. and Pidlisecky, Adam and Oldenburg, Douglas W.},
	month = dec,
	year = {2015},
	note = {Publisher: Pergamon},
	keywords = {Electromagnetics, Geophysics, Inversion, Numerical modeling, Object-oriented programming, Sensitivities},
	pages = {142--154},
	file = {PDF:/Users/lindseyjh/Zotero/storage/NZHG9KT4/Cockett et al._2015_SimPEG An open source framework for simulation and gradient based parameter estimation in geophysical applications.pdf:application/pdf},
}

@article{capello_presidents_2022,
	title = {President's {Page}: {Advancing} sustainability in {SEG}},
	volume = {41},
	issn = {1070-485X},
	doi = {10.1190/tle41010006.1},
	abstract = {In 1987, the United Nations Brundtland Commission defined sustainability as “meeting the needs of the present without compromising the ability of future generations to meet their own needs.” In this framework, development is conceived as an integrated approach to elevate the quality of life by raising economic progress with environmental protection considerations. This vision evolved into the formulation in 2015 of the United Nations 17 Sustainable Development Goals (SDGs) to mitigate the hazards of climate change and to contribute to the development of society in every aspect, establishing targets to be attained by 2030. As an example, SDG 13: Climate Action calls for initiatives to moderate climate change within development frameworks. SDG 14: Life Below Water and SDG 15: Life on Land also call for more sustainable practices in using the earth's natural resources. The world is not making progress against the SDGs fast enough to achieve all the goals within the established timeline, yet with international agreements and specific actions, the success rate is growing incrementally.},
	number = {1},
	journal = {The Leading Edge},
	author = {Capello, Maria Angela},
	year = {2022},
	pages = {6--7},
	file = {PDF:/Users/lindseyjh/Zotero/storage/3Y9K7MR2/Capello_2022_President's Page Advancing sustainability in SEG.pdf:application/pdf},
}

@incollection{fan2020improving,
	title = {Improving water security in {Mon} {State}, {Myanmar} via geophysical capacity building},
	copyright = {All rights reserved},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 2020},
	publisher = {Society of Exploration Geophysicists},
	author = {Fan, Kevin and Oldenburg, Douglas W. and Maxwell, Michael and Cowan, Devin and Kang, Seogi and Heagy, Lindsey J. and Capriotti, Joseph},
	month = sep,
	year = {2020},
	doi = {10.1190/segam2020-3428432.1},
	pages = {3355--3360},
	file = {Fan et al._2020_Improving water security in Mon State, Myanmar via geophysical capacity building.pdf:/Users/lindseyjh/Zotero/storage/QJC5N6F3/Fan et al._2020_Improving water security in Mon State, Myanmar via geophysical capacity building.pdf:application/pdf;Fan et al._2020_Improving water security in Mon State, Myanmar via geophysical capacity building(2).pdf:/Users/lindseyjh/Zotero/storage/DJN6KJD4/Fan et al._2020_Improving water security in Mon State, Myanmar via geophysical capacity building(2).pdf:application/pdf},
}

@article{heagy_geophysical_2022,
	title = {Geophysical {Inversions} to {Delineate} {Rocks} with {CO2} {Sequestration} {Potential} {Through} {Carbon} {Mineralization}},
	volume = {26.4},
	copyright = {All rights reserved},
	url = {https://fasttimesonline.co/geophysical-inversions-to-delineate-rocks-with-co-2-sequestration-potential-through-carbon-mineralization/},
	doi = {https://doi.org/10.48550/arXiv.2203.13894},
	language = {en-US},
	number = {4},
	journal = {FastTIMES Online},
	author = {Heagy, Lindsey J. and Astic, Thibaut and Capriotti, Joseph and Weis, John and Oldenburg, Douglas W},
	month = jan,
	year = {2022},
	file = {Snapshot:/Users/lindseyjh/Zotero/storage/F9P3VE7R/geophysical-inversions-to-delineate-rocks-with-co-2-sequestration-potential-through-carbon-mine.html:text/html},
}

@inproceedings{Kang2020,
	title = {Open-source geophysical software development for groundwater applications},
	copyright = {All rights reserved},
	doi = {10.1190/segam2020-3425913.1},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 2020},
	publisher = {Society of Exploration Geophysicists},
	author = {Kang, Seogi and Capriotti, Joseph and Oldenburg, Douglas W. and Heagy, Lindsey J. and Cowan, Devin},
	month = sep,
	year = {2020},
	pages = {1989--1993},
	file = {PDF:/Users/lindseyjh/Zotero/storage/2LAIANYJ/Kang et al._2020_Open-source geophysical software development for groundwater applications(2).pdf:application/pdf},
}

@inproceedings{kang_time-lapse_2022,
	address = {Houston, Texas},
	title = {Time-lapse inversion of airborne electromagnetic data for monitoring saltwater intrusion in the {Salinas} {Valley} of {California}, {USA}},
	url = {https://library.seg.org/doi/10.1190/image2022-3750766.1},
	doi = {10.1190/image2022-3750766.1},
	abstract = {Motivated by the two AEM data sets acquired in 2017 and 2019 at the Salinas Valley of California, in this study, we developed a time-lapse inversion approach that can incorporate the existing saltwater intrusion (SWI) model and the well data. The well data, which included resistivity logs, drillers’ logs, and salinity measurements were used to build a relationship between resistivity and hydrogeologic parameters. This relationship allowed us to convert hydraulic conductivity and porosity distributions obtained from the SWI model to a resistivity distribution with a low salinity ({\textasciitilde}200 mg/L). This resistivity distribution constrained the time-lapse inversion process such that estimated resistivity models at two times were favored to be close to the reference distribution. The recovered AEM resistivity model from the inversion was compared to the SWI resistivity model converted from the salinity distribution from the SWI model.},
	language = {en},
	urldate = {2022-10-11},
	booktitle = {Second {International} {Meeting} for {Applied} {Geoscience} \& {Energy}},
	publisher = {Society of Exploration Geophysicists and American Association of Petroleum Geologists},
	author = {Kang, Seogi and Knight, Rosemary},
	month = aug,
	year = {2022},
	pages = {3125--3127},
	file = {Kang and Knight - 2022 - Time-lapse inversion of airborne electromagnetic d.pdf:/Users/lindseyjh/Zotero/storage/SV855ZWW/Kang and Knight - 2022 - Time-lapse inversion of airborne electromagnetic d.pdf:application/pdf},
}

@inproceedings{rocklin_dask_2015,
	address = {Austin, Texas},
	title = {Dask: {Parallel} {Computation} with {Blocked} algorithms and {Task} {Scheduling}},
	shorttitle = {Dask},
	url = {https://conference.scipy.org/proceedings/scipy2015/matthew_rocklin.html},
	doi = {10.25080/Majora-7b98e3ed-013},
	abstract = {Dask enables parallel and out-of-core computation. We couple blocked algorithms with dynamic and memory aware task scheduling to achieve a parallel and out-of-core NumPy clone. We show how this extends the effective scale of modern hardware to larger datasets and discuss how these ideas can be more broadly applied to other parallel collections.},
	language = {en},
	urldate = {2023-04-09},
	author = {Rocklin, Matthew},
	year = {2015},
	pages = {126--132},
	file = {Rocklin - 2015 - Dask Parallel Computation with Blocked algorithms.pdf:/Users/lindseyjh/Zotero/storage/QGIM4I8K/Rocklin - 2015 - Dask Parallel Computation with Blocked algorithms.pdf:application/pdf},
}

@article{wei_3d_2022,
	title = {{3D} probabilistic geology differentiation based on airborne geophysics, mixed {Lp} norm joint inversion, and physical property measurements},
	volume = {87},
	issn = {0016-8033},
	url = {https://doi.org/10.1190/geo2021-0833.1},
	doi = {10.1190/geo2021-0833.1},
	abstract = {The physical property models obtained from geophysical inversions can be converted to a 3D quasi-geology model via a process called geology differentiation. Recent works indicate that the geology differentiation can help maximize the value of the information contained in geophysical data. However, it remains largely unexplored as to how to quantify the uncertainties of a 3D quasi-geology model. We approach this problem by using a recently developed mixed Lp norm regularization and a priori physical property measurements. We use mixed Lp norm joint inversion to construct a large sequence of physical property models based on the Gzz component of the airborne gravity gradient and magnetic measurements. The available physical property measurements are used to determine which physical property models to accept. We then construct a sequence of 3D quasi-geology models by performing the geology differentiation for all of the accepted models, which allows us to compute the probabilities of our geology differentiation results. We apply our approach to a set of field data collected over the Decorah area located in northeast Iowa. We successfully quantify the uncertainties of the spatial extents for the identified geologic units and compute probabilities of geologic units at any location in our study area. The proposed workflow has broad implications for 3D geologic model building based on multiple geophysical and/or rock sample measurements.},
	number = {4},
	urldate = {2023-08-13},
	journal = {Geophysics},
	author = {Wei, Xiaolong and Sun, Jiajia},
	month = jun,
	year = {2022},
	pages = {K19--K33},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/AUNBAHVC/Wei and Sun - 2022 - 3D probabilistic geology differentiation based on .pdf:application/pdf;Snapshot:/Users/lindseyjh/Zotero/storage/SE5CADKF/3D-probabilistic-geology-differentiation-based-on.html:text/html},
}

@article{gentemann_why_2023,
	title = {Why {NASA} and federal agencies are declaring this the {Year} of {Open} {Science}},
	volume = {613},
	copyright = {2023 Springer Nature Limited},
	url = {https://www.nature.com/articles/d41586-023-00019-y},
	doi = {10.1038/d41586-023-00019-y},
	abstract = {Here’s how NASA is incentivizing open science, and how you can too.},
	language = {en},
	number = {7943},
	urldate = {2023-09-17},
	journal = {Nature},
	author = {Gentemann, Chelle},
	month = jan,
	year = {2023},
	note = {Bandiera\_abtest: a
Cg\_type: World View
Number: 7943
Publisher: Nature Publishing Group
Subject\_term: Society, Research management, Lab life},
	keywords = {Lab life, Research management, Society},
	pages = {217--217},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/Y69ZFVJF/Gentemann - 2023 - Why NASA and federal agencies are declaring this t.pdf:application/pdf;Snapshot:/Users/lindseyjh/Zotero/storage/LP7XG3BU/d41586-023-00019-y.html:text/html},
}

@misc{unesco_introduction_2023,
	title = {An introduction to the {UNESCO} {Recommendation} on {Open} {Science} - {UNESCO} {Digital} {Library}},
	url = {https://unesdoc.unesco.org/ark:/48223/pf0000383771},
	doi = {https://doi.org/10.54677/XOIR1696},
	urldate = {2023-09-17},
	author = {UNESCO},
	year = {2023},
	file = {An introduction to the UNESCO Recommendation on Op.pdf:/Users/lindseyjh/Zotero/storage/7JL2TMB8/An introduction to the UNESCO Recommendation on Op.pdf:application/pdf;An introduction to the UNESCO Recommendation on Open Science - UNESCO Digital Library:/Users/lindseyjh/Zotero/storage/IWYCVMFY/pf0000383771.html:text/html},
}

@misc{open_source_initiative_open_2006,
	title = {The {Open} {Source} {Definition}},
	url = {https://opensource.org/osd/},
	abstract = {Introduction Open source doesn’t just mean access to the source code. The distribution terms of open-source software must comply with the following criteria: 1. Free Redistribution The licens…},
	language = {en-US},
	urldate = {2023-09-23},
	journal = {Open Source Initiative},
	author = {{Open Source Initiative}},
	month = jul,
	year = {2006},
	file = {Snapshot:/Users/lindseyjh/Zotero/storage/ZTJU33YI/osd.html:text/html},
}

@misc{awesome-open-geoscience,
	title = {softwareunderground/awesome-open-geoscience},
	shorttitle = {softwareunderground/awesome-open-geoscience},
	url = {https://zenodo.org/record/8354180},
	abstract = {Alpha release to test integration with Zenodo If this works will do another with better references to all contributors. Might as part of GitHub action?},
	urldate = {2023-09-24},
	publisher = {Zenodo},
	author = {Gosses, Justin and Dramsch, Jesper and Bianco, Evan and Werthmüller, Dieter and Moodie, Andrew and Sullivan, Bane and Niccoli, Matteo and Uieda, Leonardo and eMHa and Caté, Antoine and Nesbitt, Ian and Botella, Arnaud and Wade, David and Gravey, Mathieu and Hall, Matt and Müller, Sebastian and Svendsen, Per Olav Eide and Oliveira, Rodolfo and Cockett, Rowan and Abernathey, Ryan and Tober, Brandon S. and Kirkby, Alison and Giroux, Bernard and Tyson, Blue and Quinn, Daven and Valters, Declan and Ooi, Didi and Möller, Egil and Smaï, Farid and Ziegler, Fernando E.},
	month = sep,
	year = {2023},
	doi = {10.5281/zenodo.8354180},
	file = {Zenodo Snapshot:/Users/lindseyjh/Zotero/storage/3JJYL77S/8354180.html:text/html},
}

@article{wessel_free_1991,
	title = {Free software helps map and display data},
	volume = {72},
	copyright = {©1991. American Geophysical Union. All Rights Reserved.},
	issn = {2324-9250},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/90EO00319},
	doi = {10.1029/90EO00319},
	abstract = {When creating camera-ready figures, most scientists are familiar with the sequence of raw data → processing → final illustration and with the spending of large sums of money to finalize papers for submission to scientific journals, prepare proposals, and create overheads and slides for various presentations. This process can be tedious and is often done manually, since available commercial or in-house software usually can do only part of the job. To expedite this process, we introduce the Generic Mapping Tools (GMT), which is a free, public domain software package that can be used to manipulate columns of tabular data, time series, and gridded data sets and to display these data in a variety of forms ranging from simple x-y plots to maps and color, perspective, and shaded-relief illustrations. GMT uses the PostScript page description language, which can create arbitrarily complex images in gray tones or 24-bit true color by superimposing multiple plot files. Line drawings, bitmapped images, and text can be easily combined in one illustration. PostScript plot files are device-independent, meaning the same file can be printed at 300 dots per inch (dpi) on an ordinary laserwriter or at 2470 dpi on a phototypesetter when ultimate quality is needed. GMT software is written as a set of UNIX tools and is totally self contained and fully documented. The system is offered free of charge to federal agencies and nonprofit educational organizations worldwide and is distributed over the computer network Internet.},
	language = {en},
	number = {41},
	urldate = {2023-09-26},
	journal = {Eos, Transactions American Geophysical Union},
	author = {Wessel, Paul and Smith, Walter H. F.},
	year = {1991},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/90EO00319},
	pages = {441--446},
}

@article{stockwell_cwpsu_1999,
	title = {The {CWP}/{SU}: {Seismic} {Un}*x package},
	volume = {25},
	issn = {0098-3004},
	shorttitle = {The {CWP}/{SU}},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300498001459},
	doi = {10.1016/S0098-3004(98)00145-9},
	number = {4},
	urldate = {2023-09-26},
	journal = {Computers \& Geosciences},
	author = {Stockwell, John W.},
	month = may,
	year = {1999},
	keywords = {Geophysics, Seismic, Data processing, Code},
	pages = {415--419},
	file = {ScienceDirect Snapshot:/Users/lindseyjh/Zotero/storage/CCYYDAHW/S0098300498001459.html:text/html},
}

@article{constable_occams_1987,
	title = {Occam’s inversion: {A} practical algorithm for generating smooth models from electromagnetic sounding data},
	volume = {52},
	issn = {0016-8033, 1942-2156},
	shorttitle = {Occam’s inversion},
	url = {https://library.seg.org/doi/10.1190/1.1442303},
	doi = {10.1190/1.1442303},
	abstract = {The inversion of electromagnetic sounding data does not yield a unique solution, but inevitably a single model to interpret the observations is sought. We recommend that this model be as simple, or smooth, as possible, in order to reduce the temptation to overinterpret the data and to eliminate arbitrary discontinuities in simple layered models. To obtain smooth models, the nonlinear forward problem is linearized about a starting model in the usual way, but it is then solved explicitly for the desired model rather than for a model correction. By parameterizing the model in terms of its first or second derivative with depth, the minimum norm solution yields the smoothest possible model.},
	language = {en},
	number = {3},
	urldate = {2023-09-26},
	journal = {GEOPHYSICS},
	author = {Constable, Steven C. and Parker, Robert L. and Constable, Catherine G.},
	month = mar,
	year = {1987},
	pages = {289--300},
	file = {Constable et al. - 1987 - Occam’s inversion A practical algorithm for gener.pdf:/Users/lindseyjh/Zotero/storage/4Z93BTSA/Constable et al. - 1987 - Occam’s inversion A practical algorithm for gener.pdf:application/pdf},
}

@misc{langevin_modflow_2017,
	title = {{MODFLOW} 6, the {U}.{S}. {Geological} {Survey} {Modular} {Hydrologic} {Model}},
	url = {https://water.usgs.gov/ogw/modflow/MODFLOW.html},
	abstract = {MODFLOW is a popular open-source groundwater flow model distributed by the U.S. Geological Survey. For over 30 years, the MODFLOW program has been widely used by academics, private consultants, and government scientists to accurately, reliably, and efficiently simulate groundwater flow. With time, growing interest in surface and groundwater interactions, local refinement with nested and unstructured grids, karst groundwater flow, solute transport, and saltwater intrusion, has led to the development of numerous MODFLOW versions. Although these MODFLOW versions are often based on the core MODFLOW version (previously MODFLOW-2005), there are often incompatibilities that restrict their use with other MODFLOW versions. In many cases, development of these alternative MODFLOW versions has been challenging due to the underlying program structure, which was designed for the simulation of a single groundwater flow model using a regular MODFLOW grid consisting of layers, rows, and columns. A new object-oriented program and underlying framework called MODFLOW 6 was developed to provide a platform for supporting multiple models and multiple types of models within the same simulation. This version of MODFLOW is labeled with a \&amp;amp;amp;amp;amp;quot;6\&amp;amp;amp;amp;amp;quot; because it is the sixth core version of MODFLOW to be released by the USGS (previous core versions were released in 1984, 1988, 1996, 2000, and 2005). In the new design, any number of models can be included in a simulation. These models can be independent of one another with no interaction, they can exchange information with one another, or they can be tightly coupled at the matrix level by adding them to the same numerical solution. Transfer of information between models is isolated to exchange objects, which allow models to be developed and used independently of one another. Within this new framework, a regional-scale groundwater model may be coupled with multiple local-scale groundwater models. Or, a surface-water flow model could be coupled to multiple groundwater flow models. The framework naturally allows for future extensions to include the simulation of solute transport.},
	urldate = {2023-09-26},
	publisher = {U.S. Geological Survey},
	author = {Langevin, Christian D. and Hughes, Joseph D. and Banta, Edward and Provost, Alden and Niswonger, Richard and Panday, Sorab},
	year = {2017},
	doi = {10.5066/F76Q1VQV},
	keywords = {groundwater, MODFLOW, Newton-Raphson, local-grid refinement, USGS},
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	copyright = {2016 The Author(s)},
	issn = {2052-4463},
	url = {https://www.nature.com/articles/sdata201618},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	language = {en},
	number = {1},
	urldate = {2023-09-30},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = mar,
	year = {2016},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Publication characteristics, Research data},
	pages = {160018},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/ZVZGNE6L/Wilkinson et al. - 2016 - The FAIR Guiding Principles for scientific data ma.pdf:application/pdf},
}

@inproceedings{langenkamp_how_2022,
	address = {Oxford United Kingdom},
	title = {How {Open} {Source} {Machine} {Learning} {Software} {Shapes} {AI}},
	isbn = {978-1-4503-9247-1},
	url = {https://dl.acm.org/doi/10.1145/3514094.3534167},
	doi = {10.1145/3514094.3534167},
	abstract = {If we want a future where AI serves a plurality of interests, then we should pay attention to the factors that drive its success. While others have studied the importance of data, hardware, and models in directing the trajectory of AI, we argue that open source software is a neglected factor shaping AI as a discipline. We start with the observation that almost all AI research and applications are built on machine learning open source software (MLOSS). This paper presents three contributions. First, it quantifies the outsized impact of MLOSS by using Github contributions data. By contrasting the costs of MLOSS and its economic benefits, we find that the average dollar of MLOSS investment corresponds to at least \$100 of global economic value created, corresponding to \$30B of economic value created this year. Second, we leverage interviews with AI researchers and developers to develop a causal model of the effect of open sourcing on economic value. We argue that open sourcing creates value through three primary mechanisms: standardization of MLOSS tools, increased experimentation in AI research, and creation of communities. Finally, we consider the incentives for developing MLOSS and the broader implications of these effects. We intend this paper to be useful for technologists and academics who want to analyze and critique AI, and policymakers who want to better understand and regulate AI systems.},
	language = {en},
	urldate = {2023-09-30},
	booktitle = {Proceedings of the 2022 {AAAI}/{ACM} {Conference} on {AI}, {Ethics}, and {Society}},
	publisher = {ACM},
	author = {Langenkamp, Max and Yue, Daniel N.},
	month = jul,
	year = {2022},
	pages = {385--395},
	file = {Langenkamp and Yue - 2022 - How Open Source Machine Learning Software Shapes A.pdf:/Users/lindseyjh/Zotero/storage/PV4TSVAN/Langenkamp and Yue - 2022 - How Open Source Machine Learning Software Shapes A.pdf:application/pdf},
}

@book{european_commission_impact_2021,
	address = {LU},
	title = {The impact of open source software and hardware on technological independence, competitiveness and innovation in the {EU} economy: final study report.},
	shorttitle = {The impact of open source software and hardware on technological independence, competitiveness and innovation in the {EU} economy},
	url = {https://data.europa.eu/doi/10.2759/430161},
	language = {en},
	urldate = {2023-09-30},
	publisher = {Publications Office},
	author = {{European Commission}},
	year = {2021},
	file = {European Commission. Directorate General for Communications Networks, Content and Technology. - 2021 - The impact of open source software and hardware on.pdf:/Users/lindseyjh/Zotero/storage/683MVM8Q/European Commission. Directorate General for Communications Networks, Content and Technology. - 2021 - The impact of open source software and hardware on.pdf:application/pdf},
}

@inproceedings{banks_measuring_2022,
	title = {Measuring the {Impact} of {Open} {Source} {Software} {Innovation} {Using} {Network} {Analysis} on {GitHub} {Hosted} {Python} {Packages}},
	url = {https://ieeexplore.ieee.org/document/9799290},
	doi = {10.1109/SIEDS55548.2022.9799290},
	abstract = {Open Source Software (OSS) is computer software that has its source code publicly available with a license in which the copyright holder provides the rights to study, change, and distribute the software to anyone and for any purpose. Despite its extensive use, reliable measures of the scope and impact of OSS are scarce. In this paper, we focus on packages developed for Python programming language as it is one of the most widely-used languages mainly due to its flexibility and simple syntax that makes its framework easy to learn and share. We aim to develop a framework to measure the impact of Python packages listed on Package Index (PyPI.org). We use data from GitHub repositories (where these packages are developed) to obtain information about their development activity e.g., lines of code. Our goal is to identify influential actors, e.g., packages, developers, countries by using the impact measures. We use network-based and OSS-based measures such as number of downloads. Network-based statistics include centrality measures such as degree, and eigenvector centrality. Moreover, we calcu-late the cost of OSS as intangible capital using the COCOMO II model [1] to determine the cost of development and study the relationship between development cost and impact of Python projects. The findings show that the number of downloads for a package are correlated with the centrality statistics, supporting the hypothesis that the most influential are the most downloaded as well. We show which packages are saving on development cost by leveraging dependencies. This framework and measures can be applied more broadly to the OSS ecosystem and contribute to the National Science Foundation (NSF) policy indicators for measurement of innovation.},
	urldate = {2023-09-30},
	booktitle = {2022 {Systems} and {Information} {Engineering} {Design} {Symposium} ({SIEDS})},
	author = {Banks, Derek and Leonard, Camille and Narayan, Shilpa and Thompson, Nicholas and Kramer, Brandon and Korkmaz, Gizem},
	month = apr,
	year = {2022},
	pages = {110--115},
	file = {IEEE Xplore Abstract Record:/Users/lindseyjh/Zotero/storage/XSMVCCBN/9799290.html:text/html;IEEE Xplore Full Text PDF:/Users/lindseyjh/Zotero/storage/CUY3Q3B9/Banks et al. - 2022 - Measuring the Impact of Open Source Software Innov.pdf:application/pdf},
}

@article{doyoro_review_2022,
	title = {A review of open software resources in python for electrical resistivity modelling},
	volume = {9},
	issn = {2196-4092},
	url = {https://doi.org/10.1186/s40562-022-00214-1},
	doi = {10.1186/s40562-022-00214-1},
	abstract = {Geophysical modelling performs to obtain subsurface structures in agreement with measured data. Freeware algorithms for geoelectrical data inversion have not been widely used in geophysical communities; however, different open-source modelling/inversion algorithms were developed in recent years. In this study, we review the structures and applications of openly Python-based inversion packages, such as pyGIMLi (Python Library for Inversion and Modelling in Geophysics), BERT (Boundless Electrical Resistivity Tomography), ResIPy (Resistivity and Induced Polarization with Python), pyres (Python wrapper for electrical resistivity modelling), and SimPEG (Simulation and Parameter Estimation in Geophysics). In addition, we examine the recovering ability of pyGIMLi, BERT, ResIPy, and SimPEG freeware through inversion of the same synthetic model forward responses. A versatile pyGIMLi freeware is highly suitable for various geophysical data inversion. The SimPEG framework is developed to allow the user to explore, experiment with, and iterate over multiple approaches to the inverse problem. In contrast, BERT, pyres, and ResIPy are exclusively designed for geoelectric data inversion. BERT and pyGIMLi codes can be easily modified for the intended applications. Both pyres and ResIPy use the same mesh designs and inversion algorithms, but pyres uses scripting language, while ResIPy uses a graphical user interface (GUI) that removes the need for text inputs. Our numerical modelling shows that all the tested inversion freeware could be effective for relatively larger targets. pyGIMLi and BERT could also obtain reasonable model resolutions and anomaly accuracies for small-sized subsurface structures. Based on the heterogeneous layered model and experimental target scenario results, the geoelectrical data inversion could be more effective in pyGIMLi, BERT, and SimPEG freeware packages. Moreover, this study can provide insight into implementing suitable inversion freeware for reproducible geophysical research, mainly for geoelectrical modelling.},
	number = {1},
	urldate = {2023-10-01},
	journal = {Geoscience Letters},
	author = {Doyoro, Yonatan Garkebo and Chang, Ping-Yu and Puntu, Jordi Mahardika and Lin, Ding-Jiun and Van Huu, Tran and Rahmalia, Diah Ayu and Shie, Meng-Shiun},
	month = jan,
	year = {2022},
	keywords = {BERT, Inversion freeware, pyGIMLi, Pyres, ResIPy, Resistivity modelling, SimPEG},
	pages = {3},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/73SEWBVZ/Doyoro et al. - 2022 - A review of open software resources in python for .pdf:application/pdf},
}

@misc{noauthor_improving_nodate,
	title = {Improving water security in {Mon} {State}, {Myanmar} via geophysical capacity building},
	url = {https://library.seg.org/doi/epdfplus/10.1190/segam2020-3428432.1},
	language = {en},
	urldate = {2023-10-02},
	doi = {10.1190/segam2020-3428432.1},
	file = {Snapshot:/Users/lindseyjh/Zotero/storage/NA62VVVI/segam2020-3428432.html:text/html},
}

@misc{noauthor_role_nodate,
	title = {The role of open source resources and practices in capacity building},
	url = {https://library.seg.org/doi/epdfplus/10.1190/segam2020-3428404.1},
	language = {en},
	urldate = {2023-10-02},
	doi = {10.1190/segam2020-3428404.1},
	file = {Snapshot:/Users/lindseyjh/Zotero/storage/4CIKG2YB/segam2020-3428404.html:text/html},
}

@misc{noauthor_open-source_nodate,
	title = {Open-source geophysical software development for groundwater applications},
	url = {https://library.seg.org/doi/epdfplus/10.1190/segam2020-3425913.1},
	language = {en},
	urldate = {2023-10-02},
	doi = {10.1190/segam2020-3425913.1},
	file = {Snapshot:/Users/lindseyjh/Zotero/storage/EBZ7H3TR/segam2020-3425913.html:text/html},
}

@article{blanchy_resipy_2020,
	title = {{ResIPy}, an intuitive open source software for complex geoelectrical inversion/modeling},
	volume = {137},
	issn = {00983004},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0098300419308192},
	doi = {10.1016/j.cageo.2020.104423},
	abstract = {Electrical resistivity tomography (ERT) and induced polarization (IP) methods are now widely used in many interdisciplinary projects. Although field surveys using these methods are relatively straightforward, ERT and IP data require the application of inverse methods prior to any interpretation. Several established non-commercial inversion codes exist, but they typically require advanced knowledge to use effectively. ResIPy was developed to provide a more intuitive, user-friendly, approach to inversion of geoelectrical data, using an open source graphical user interface (GUI) and a Python application programming interface (API). ResIPy utilizes the mature R2/cR2 inversion codes for ERT and IP, respectively. The ResIPy GUI facilitates data importing, data filtering, error modeling, mesh generation, data inversion and plotting of inverse models. Furthermore, the easy to use design of ResIPy and the help provided inside makes it an effective educational tool. This paper highlights the rationale and structure behind the interface, before demonstrating its capabilities in a range of environmental problems. Specifically, we demonstrate the ease at which ResIPy deals with topography, advanced data pro­ cessing, the ability to fix and constrain regions of known geoelectrical properties, time-lapse analysis and the capability for forward modeling and survey design.},
	language = {en},
	urldate = {2023-10-14},
	journal = {Computers \& Geosciences},
	author = {Blanchy, Guillaume and Saneiyan, Sina and Boyd, Jimmy and McLachlan, Paul and Binley, Andrew},
	month = apr,
	year = {2020},
	pages = {104423},
	file = {Blanchy et al. - 2020 - ResIPy, an intuitive open source software for comp.pdf:/Users/lindseyjh/Zotero/storage/A6ZEZC9F/Blanchy et al. - 2020 - ResIPy, an intuitive open source software for comp.pdf:application/pdf},
}

@article{blanchy_resipy_2020-1,
	title = {{ResIPy}, an intuitive open source software for complex geoelectrical inversion/modeling},
	volume = {137},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300419308192},
	doi = {10.1016/j.cageo.2020.104423},
	abstract = {Electrical resistivity tomography (ERT) and induced polarization (IP) methods are now widely used in many interdisciplinary projects. Although field surveys using these methods are relatively straightforward, ERT and IP data require the application of inverse methods prior to any interpretation. Several established non-commercial inversion codes exist, but they typically require advanced knowledge to use effectively. ResIPy was developed to provide a more intuitive, user-friendly, approach to inversion of geoelectrical data, using an open source graphical user interface (GUI) and a Python application programming interface (API). ResIPy utilizes the mature R2/cR2 inversion codes for ERT and IP, respectively. The ResIPy GUI facilitates data importing, data filtering, error modeling, mesh generation, data inversion and plotting of inverse models. Furthermore, the easy to use design of ResIPy and the help provided inside makes it an effective educational tool. This paper highlights the rationale and structure behind the interface, before demonstrating its capabilities in a range of environmental problems. Specifically, we demonstrate the ease at which ResIPy deals with topography, advanced data processing, the ability to fix and constrain regions of known geoelectrical properties, time-lapse analysis and the capability for forward modeling and survey design.},
	urldate = {2023-10-14},
	journal = {Computers \& Geosciences},
	author = {Blanchy, Guillaume and Saneiyan, Sina and Boyd, Jimmy and McLachlan, Paul and Binley, Andrew},
	month = apr,
	year = {2020},
	keywords = {Inversion, Geophysics, Electrical resistivity tomography, Data filtering, Induced polarization, R2/cR2},
	pages = {104423},
}

@article{biondi_object-oriented_2021,
	title = {An object-oriented optimization framework for large-scale inverse problems},
	volume = {154},
	issn = {0098-3004},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300421000935},
	doi = {10.1016/j.cageo.2021.104790},
	abstract = {We present an object-oriented optimization framework that can be employed to solve small- and large-scale problems based on the concept of vectors and operators. By using such a strategy, we implement different iterative optimization algorithms that can be used in combination with architecture-independent vectors and operators, allowing the minimization of single-machine or cluster-based problems with a unique codebase. We implement a Python library following the described structure with a user-friendly interface that is designed to seamlessly scale to high-performance-computing (HPC) environments. We demonstrate its flexibility and scalability on multiple inverse problems, where convex and non-convex objective functions are optimized with different iterative algorithms.},
	urldate = {2023-10-14},
	journal = {Computers \& Geosciences},
	author = {Biondi, Ettore and Barnier, Guillaume and Clapp, Robert G. and Picetti, Francesco and Farris, Stuart},
	month = sep,
	year = {2021},
	keywords = {Inversion, Python, Large-scale problems, Object-oriented, Optimization},
	pages = {104790},
}

@article{key_mare2dem_2016,
	title = {{MARE2DEM}: a 2-{D} inversion code for controlled-source electromagnetic and magnetotelluric data},
	volume = {207},
	issn = {0956-540X},
	shorttitle = {{MARE2DEM}},
	url = {https://doi.org/10.1093/gji/ggw290},
	doi = {10.1093/gji/ggw290},
	abstract = {This work presents MARE2DEM, a freely available code for 2-D anisotropic inversion of magnetotelluric (MT) data and frequency-domain controlled-source electromagnetic (CSEM) data from onshore and offshore surveys. MARE2DEM parametrizes the inverse model using a grid of arbitrarily shaped polygons, where unstructured triangular or quadrilateral grids are typically used due to their ease of construction. Unstructured grids provide significantly more geometric flexibility and parameter efficiency than the structured rectangular grids commonly used by most other inversion codes. Transmitter and receiver components located on topographic slopes can be tilted parallel to the boundary so that the simulated electromagnetic fields accurately reproduce the real survey geometry. The forward solution is implemented with a goal-oriented adaptive finite-element method that automatically generates and refines unstructured triangular element grids that conform to the inversion parameter grid, ensuring accurate responses as the model conductivity changes. This dual-grid approach is significantly more efficient than the conventional use of a single grid for both the forward and inverse meshes since the more detailed finite-element meshes required for accurate responses do not increase the memory requirements of the inverse problem. Forward solutions are computed in parallel with a highly efficient scaling by partitioning the data into smaller independent modeling tasks consisting of subsets of the input frequencies, transmitters and receivers. Non-linear inversion is carried out with a new Occam inversion approach that requires fewer forward calls. Dense matrix operations are optimized for memory and parallel scalability using the ScaLAPACK parallel library. Free parameters can be bounded using a new non-linear transformation that leaves the transformed parameters nearly the same as the original parameters within the bounds, thereby reducing non-linear smoothing effects. Data balancing normalization weights for the joint inversion of two or more data sets encourages the inversion to fit each data type equally well. A synthetic joint inversion of marine CSEM and MT data illustrates the algorithm's performance and parallel scaling on up to 480 processing cores. CSEM inversion of data from the Middle America Trench offshore Nicaragua demonstrates a real world application. The source code and MATLAB interface tools are freely available at http://mare2dem.ucsd.edu.},
	number = {1},
	urldate = {2023-10-14},
	journal = {Geophysical Journal International},
	author = {Key, Kerry},
	month = oct,
	year = {2016},
	pages = {571--588},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/4S7H6SXQ/Key - 2016 - MARE2DEM a 2-D inversion code for controlled-sour.pdf:application/pdf},
}

@article{mardan_pyfwi_2023,
	title = {{PyFWI}: {A} {Python} package for full-waveform inversion and reservoir monitoring},
	volume = {22},
	issn = {2352-7110},
	shorttitle = {{PyFWI}},
	url = {https://www.sciencedirect.com/science/article/pii/S2352711023000808},
	doi = {10.1016/j.softx.2023.101384},
	abstract = {Full-waveform inversion (FWI) of seismic data is a technique that can be used to image the subsurface as well as to monitor time-lapse changes in the subsurface (TL-FWI). PyFWI is a package that has been designed to carry out FWI and TL-FWI efficiently on GPU for research purposes. Several time-lapse strategies are implemented in PyFWI, such as parallel, double-difference, cascaded, central-difference, cross-updating, simultaneous, and weighted-average. An important challenge of TL-FWI is the crosstalk between parameters across different vintages. To alleviate this problem, PyFWI allows using different parameterizations. PyFWI is written in Python and relies on OpenCL for enabling calculations on GPUs, which leads to significant reduction of computation time compared to CPU implementation. Using OpenCL makes PyFWI portable across systems built with GPUs from different manufacturers.},
	urldate = {2023-10-14},
	journal = {SoftwareX},
	author = {Mardan, Amir and Giroux, Bernard and Fabien-Ouellet, Gabriel},
	month = may,
	year = {2023},
	keywords = {Python, Full-waveform inversion, GPU programming, Reservoir monitoring, Time-lapse seismic},
	pages = {101384},
	file = {ScienceDirect Full Text PDF:/Users/lindseyjh/Zotero/storage/DT28KEDL/Mardan et al. - 2023 - PyFWI A Python package for full-waveform inversio.pdf:application/pdf},
}

@misc{hewett_pysitpysit_2020,
	title = {pysit/pysit: v1.0.1},
	copyright = {Open Access},
	shorttitle = {pysit/pysit},
	url = {https://zenodo.org/record/3603367},
	abstract = {No description provided.},
	urldate = {2023-10-14},
	publisher = {Zenodo},
	author = {Hewett, Russell J. and Willemsen, Bram and Lebrat, Leo and Paris, Antoine and Grady, Thomas and {Mtcli} and {Gstuartstats}},
	month = jan,
	year = {2020},
	doi = {10.5281/ZENODO.3603367},
}

@article{ruthotto_jinv--flexible_2017,
	title = {{jInv}--a {Flexible} {Julia} {Package} for {PDE} {Parameter} {Estimation}},
	volume = {39},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/abs/10.1137/16M1081063},
	doi = {10.1137/16M1081063},
	abstract = {Full waveform inversion (FWI) is a process in which seismic numerical simulations are fit to observed data by changing the wave velocity model of the medium under investigation. The problem is nonlinear, and therefore optimization techniques have been used to find a reasonable solution to the problem. The main problem in fitting the data is the lack of low spatial frequencies. This deficiency often leads to a local minimum and to nonplausible solutions. In this work we explore how to obtain low-frequency information for FWI. Our approach involves augmenting FWI with travel time tomography, which has low-frequency features. By jointly inverting these two problems we enrich FWI with information that can replace low-frequency data. In addition, we use high-order regularization, in a preliminary inversion stage, to prevent high-frequency features from polluting our model in the initial stages of the reconstruction. This regularization also promotes the nondominant low-frequency modes that exist in the FWI sensitivity. By applying a joint FWI and travel time inversion we are able to obtain a smooth model than can later be used to recover a good approximation for the true model. A second contribution of this paper involves the acceleration of the main computational bottleneck in FWI---the solution of the Helmholtz equation. We show that the solution time can be reduced by solving the equation for multiple right-hand sides using block multigrid preconditioned Krylov methods.},
	number = {5},
	urldate = {2023-10-14},
	journal = {SIAM Journal on Scientific Computing},
	author = {Ruthotto, Lars and Treister, Eran and Haber, Eldad},
	month = jan,
	year = {2017},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {S702--S722},
	file = {Submitted Version:/Users/lindseyjh/Zotero/storage/S2GF9VFP/Ruthotto et al. - 2017 - jInv--a Flexible Julia Package for PDE Parameter E.pdf:application/pdf},
}

@inproceedings{stanton_seismic_2016,
	title = {Seismic {Data} {Analysis} in {Julia}},
	volume = {2016},
	url = {https://www.earthdoc.org/content/papers/10.3997/2214-4609.201601652},
	doi = {10.3997/2214-4609.201601652},
	abstract = {Summary A new programming language for scientific computing has undergone rapid development since 2012. The language is named Julia– perhaps a reference to the beautiful fractal patterns of the Julia set. Julia is a high level programming language with an extensive library of mathematical functions that is easy to code and share with others. However, unlike other high level languages it offers C-like performance. It is an open source language with a large community of users and developers with a built-in package manager. The Signal Analysis and Imaging Group (SAIG) has recently released a seismic data processing package named Seismic.jl that contains utilities for reading and manipulating seismic data. We believe Julia is a great new language for research and teaching in the geosciences.},
	language = {en},
	urldate = {2023-10-14},
	publisher = {European Association of Geoscientists \& Engineers},
	author = {Stanton, K. A. and Sacchi, M. D. and Kazemi, N.},
	month = may,
	year = {2016},
	note = {ISSN: 2214-4609
Issue: 1},
	pages = {1--5},
	file = {Snapshot:/Users/lindseyjh/Zotero/storage/C2822IGL/2214-4609.html:text/html},
}

@article{krieger_mtpy_2014,
	title = {{MTpy}: {A} {Python} toolbox for magnetotellurics},
	volume = {72},
	issn = {0098-3004},
	shorttitle = {{MTpy}},
	url = {https://www.sciencedirect.com/science/article/pii/S0098300414001794},
	doi = {10.1016/j.cageo.2014.07.013},
	abstract = {We present the software package MTpy that allows handling, processing, and imaging of magnetotelluric (MT) data sets. Written in Python, the code is open source, containing sub-packages and modules for various tasks within the standard MT data processing and handling scheme. Besides the independent definition of classes and functions, MTpy provides wrappers and convenience scripts to call standard external data processing and modelling software. In its current state, modules and functions of MTpy work on raw and pre-processed MT data. However, opposite to providing a static compilation of software, we prefer to introduce MTpy as a flexible software toolbox, whose contents can be combined and utilised according to the respective needs of the user. Just as the overall functionality of a mechanical toolbox can be extended by adding new tools, MTpy is a flexible framework, which will be dynamically extended in the future. Furthermore, it can help to unify and extend existing codes and algorithms within the (academic) MT community. In this paper, we introduce the structure and concept of MTpy. Additionally, we show some examples from an everyday work-flow of MT data processing: the generation of standard EDI data files from raw electric (E-) and magnetic flux density (B-) field time series as input, the conversion into MiniSEED data format, as well as the generation of a graphical data representation in the form of a Phase Tensor pseudosection.},
	urldate = {2023-10-14},
	journal = {Computers \& Geosciences},
	author = {Krieger, Lars and Peacock, Jared R.},
	month = nov,
	year = {2014},
	keywords = {Magnetotellurics, Data processing, Open source, Python toolbox, Software},
	pages = {167--175},
}

@article{louboutin_devito_2019,
	title = {Devito (v3.1.0): an embedded domain-specific language for finite differences and geophysical exploration},
	volume = {12},
	issn = {1991-959X},
	shorttitle = {Devito (v3.1.0)},
	url = {https://gmd.copernicus.org/articles/12/1165/2019/},
	doi = {10.5194/gmd-12-1165-2019},
	abstract = {We introduce Devito, a new domain-specific language for implementing high-performance finite-difference partial differential equation solvers. The motivating application is exploration seismology for which methods such as full-waveform inversion and reverse-time migration are used to invert terabytes of seismic data to create images of the Earth's subsurface. Even using modern supercomputers, it can take weeks to process a single seismic survey and create a useful subsurface image. The computational cost is dominated by the numerical solution of wave equations and their corresponding adjoints. Therefore, a great deal of effort is invested in aggressively optimizing the performance of these wave-equation propagators for different computer architectures. Additionally, the actual set of partial differential equations being solved and their numerical discretization is under constant innovation as increasingly realistic representations of the physics are developed, further ratcheting up the cost of practical solvers. By embedding a domain-specific language within Python and making heavy use of SymPy, a symbolic mathematics library, we make it possible to develop finite-difference simulators quickly using a syntax that strongly resembles the mathematics. The Devito compiler reads this code and applies a wide range of analysis to generate highly optimized and parallel code. This approach can reduce the development time of a verified and optimized solver from months to days.},
	language = {English},
	number = {3},
	urldate = {2023-10-14},
	journal = {Geoscientific Model Development},
	author = {Louboutin, Mathias and Lange, Michael and Luporini, Fabio and Kukreja, Navjot and Witte, Philipp A. and Herrmann, Felix J. and Velesko, Paulius and Gorman, Gerard J.},
	month = mar,
	year = {2019},
	note = {Publisher: Copernicus GmbH},
	pages = {1165--1187},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/8P5F25B8/Louboutin et al. - 2019 - Devito (v3.1.0) an embedded domain-specific langu.pdf:application/pdf},
}

@article{warren_gprmax_2016,
	title = {{gprMax}: {Open} source software to simulate electromagnetic wave propagation for {Ground} {Penetrating} {Radar}},
	volume = {209},
	issn = {0010-4655},
	shorttitle = {{gprMax}},
	url = {https://www.sciencedirect.com/science/article/pii/S0010465516302533},
	doi = {10.1016/j.cpc.2016.08.020},
	abstract = {gprMax is open source software that simulates electromagnetic wave propagation, using the Finite-Difference Time-Domain (FDTD) method, for the numerical modelling of Ground Penetrating Radar (GPR). gprMax was originally developed in 1996 when numerical modelling using the FDTD method and, in general, the numerical modelling of GPR were in their infancy. Current computing resources offer the opportunity to build detailed and complex FDTD models of GPR to an extent that was not previously possible. To enable these types of simulations to be more easily realised, and also to facilitate the addition of more advanced features, gprMax has been redeveloped and significantly modernised. The original C-based code has been completely rewritten using a combination of Python and Cython programming languages. Standard and robust file formats have been chosen for geometry and field output files. New advanced modelling features have been added including: an unsplit implementation of higher order Perfectly Matched Layers (PMLs) using a recursive integration approach; diagonally anisotropic materials; dispersive media using multi-pole Debye, Drude or Lorenz expressions; soil modelling using a semi-empirical formulation for dielectric properties and fractals for geometric characteristics; rough surface generation; and the ability to embed complex transducers and targets.
Program summary
Program title: gprMax Catalogue identifier: AFBG\_v1\_0 Program summary URL:http://cpc.cs.qub.ac.uk/summaries/AFBG\_v1\_0.html Program obtainable from: CPC Program Library, Queen’s University, Belfast, N. Ireland Licensing provisions: GNU GPL v3 No. of lines in distributed program, including test data, etc.: 627180 No. of bytes in distributed program, including test data, etc.: 26762280 Distribution format: tar.gz Programming language: Python. Computer: Any computer with a Python interpreter and a C compiler. Operating system: Microsoft Windows, Mac OS X, and Linux. RAM: Problem dependent Classification: 10. External routines: Cython[1], h5py[2], matplotlib[3], NumPy[4], mpi4py[5] Nature of problem: Classical electrodynamics Solution method: Finite-Difference Time-Domain (FDTD) Running time: Problem dependent References:[1]Cython, http://www.cython.org[2]h5py, http://www.h5py.org[3]matplotlib, http://www.matplotlib.org[4]NumPy, http://www.numpy.org[5]mpi4py, http://mpi4py.scipy.org},
	urldate = {2023-10-14},
	journal = {Computer Physics Communications},
	author = {Warren, Craig and Giannopoulos, Antonios and Giannakis, Iraklis},
	month = dec,
	year = {2016},
	keywords = {Python, Open source, Computational electromagnetism, Finite-Difference Time-Domain, Ground Penetrating Radar},
	pages = {163--170},
	file = {ScienceDirect Full Text PDF:/Users/lindseyjh/Zotero/storage/NC9SYCSY/Warren et al. - 2016 - gprMax Open source software to simulate electroma.pdf:application/pdf},
}

@inproceedings{lam_numba_2015,
	address = {New York, NY, USA},
	series = {{LLVM} '15},
	title = {Numba: a {LLVM}-based {Python} {JIT} compiler},
	isbn = {978-1-4503-4005-2},
	shorttitle = {Numba},
	url = {https://dl.acm.org/doi/10.1145/2833157.2833162},
	doi = {10.1145/2833157.2833162},
	abstract = {Dynamic, interpreted languages, like Python, are attractive for domain-experts and scientists experimenting with new ideas. However, the performance of the interpreter is often a barrier when scaling to larger data sets. This paper presents a just-in-time compiler for Python that focuses in scientific and array-oriented computing. Starting with the simple syntax of Python, Numba compiles a subset of the language into efficient machine code that is comparable in performance to a traditional compiled language. In addition, we share our experience in building a JIT compiler using LLVM[1].},
	urldate = {2023-10-14},
	booktitle = {Proceedings of the {Second} {Workshop} on the {LLVM} {Compiler} {Infrastructure} in {HPC}},
	publisher = {Association for Computing Machinery},
	author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
	month = nov,
	year = {2015},
	keywords = {Python, compiler, LLVM},
	pages = {1--6},
	file = {Full Text PDF:/Users/lindseyjh/Zotero/storage/B7JRIEG6/Lam et al. - 2015 - Numba a LLVM-based Python JIT compiler.pdf:application/pdf},
}

@inproceedings{abadi_tensorflow_2016,
	address = {New York, NY, USA},
	series = {{ICFP} 2016},
	title = {{TensorFlow}: learning functions at scale},
	isbn = {978-1-4503-4219-3},
	shorttitle = {{TensorFlow}},
	url = {https://doi.org/10.1145/2951913.2976746},
	doi = {10.1145/2951913.2976746},
	abstract = {TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Its computational model is based on dataflow graphs with mutable state. Graph nodes may be mapped to different machines in a cluster, and within each machine to CPUs, GPUs, and other devices. TensorFlow supports a variety of applications, but it particularly targets training and inference with deep neural networks. It serves as a platform for research and for deploying machine learning systems across many areas, such as speech recognition, computer vision, robotics, information retrieval, and natural language processing. In this talk, we describe TensorFlow and outline some of its applications. We also discuss the question of what TensorFlow and deep learning may have to do with functional programming. Although TensorFlow is not purely functional, many of its uses are concerned with optimizing functions (during training), then with applying those functions (during inference). These functions are defined as compositions of simple primitives (as is common in functional programming), with internal data representations that are learned rather than manually designed. TensorFlow is joint work with many other people in the Google Brain team and elsewhere. More information is available at tensorflow.org.},
	urldate = {2023-10-14},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Abadi, Martín},
	month = sep,
	year = {2016},
	keywords = {distributed programming, Machine learning},
	pages = {1},
}

@incollection{capriotti_joint_2023,
	series = {{SEG} {Technical} {Program} {Expanded} {Abstracts}},
	title = {Joint inversions with the {SimPEG} framework},
	url = {https://library.seg.org/doi/abs/10.1190/image2023-3910791.1},
	urldate = {2024-01-02},
	booktitle = {Third {International} {Meeting} for {Applied} {Geoscience} \& {Energy} {Expanded} {Abstracts}},
	publisher = {Society of Exploration Geophysicists and American Association of Petroleum Geologists},
	author = {Capriotti, Joseph and Heagy, Lindsey J. and Soler, Santiago},
	month = dec,
	year = {2023},
	doi = {10.1190/image2023-3910791.1},
	keywords = {carbon storage, joint inversion, open-source},
	pages = {1678--1682},
}
